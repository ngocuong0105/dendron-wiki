{"pageProps":{"note":{"id":"6eb6qm06u6vpwbpxckyzkem","title":"Stanford CS230: Deep Learning","desc":"","updated":1686217953062,"created":1684778311163,"custom":{},"fname":"deep learning.Stanford CS230: Deep Learning","type":"note","vault":{"fsPath":"vault"},"contentHash":"f8a9dea04282c1a176db03ac088318b4","links":[],"anchors":{"key-messages":{"type":"header","text":"Key messages","value":"key-messages","line":14,"column":0,"depth":1},"lecture-1-deep-learning-overview":{"type":"header","text":"Lecture 1 Deep Learning overview","value":"lecture-1-deep-learning-overview","line":43,"column":0,"depth":1},"lecture-2-deep-learning-intuition":{"type":"header","text":"Lecture 2: Deep Learning Intuition","value":"lecture-2-deep-learning-intuition","line":60,"column":0,"depth":1},"case-study-1-day-and-night-classification":{"type":"header","text":"Case study 1: Day and Night classification","value":"case-study-1-day-and-night-classification","line":77,"column":0,"depth":2},"case-study-2-face-verification":{"type":"header","text":"Case study 2: Face verification","value":"case-study-2-face-verification","line":92,"column":0,"depth":2},"case-study-3-art-generation":{"type":"header","text":"Case study 3: Art generation","value":"case-study-3-art-generation","line":110,"column":0,"depth":2},"case-study-4-trigger-word-detection-alexa":{"type":"header","text":"Case study 4: Trigger word detection (Alexa)","value":"case-study-4-trigger-word-detection-alexa","line":127,"column":0,"depth":2},"lecture-3---full-cycle-deep-learning-projects":{"type":"header","text":"Lecture 3 - Full-Cycle Deep Learning Projects","value":"lecture-3---full-cycle-deep-learning-projects","line":138,"column":0,"depth":1},"lecture-4---adversarial-attacks--gans":{"type":"header","text":"Lecture 4 - Adversarial Attacks / GANs","value":"lecture-4---adversarial-attacks--gans","line":166,"column":0,"depth":1},"attacking-a-network-with-adversarial-examples":{"type":"header","text":"Attacking a network with adversarial examples","value":"attacking-a-network-with-adversarial-examples","line":174,"column":0,"depth":2},"defense-against-a-network-with-adversarial-examples":{"type":"header","text":"Defense against a network with adversarial examples","value":"defense-against-a-network-with-adversarial-examples","line":194,"column":0,"depth":2},"why-are-nn-vulnarable-to-adversarial-examples":{"type":"header","text":"Why are NN vulnarable to adversarial examples?","value":"why-are-nn-vulnarable-to-adversarial-examples","line":200,"column":0,"depth":2},"gan---generative-adversarial-networks":{"type":"header","text":"GAN - Generative Adversarial Networks","value":"gan---generative-adversarial-networks","line":212,"column":0,"depth":2},"gd-game":{"type":"header","text":"G/D game","value":"gd-game","line":218,"column":0,"depth":3}},"children":[],"parent":"ro9bbyftsutm88mxw6r16p5","data":{}},"body":"<h1 id=\"stanford-cs230-deep-learning\">Stanford CS230: Deep Learning<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#stanford-cs230-deep-learning\"></a></h1>\n<p><a href=\"https://www.youtube.com/playlist?list=PLoROMvodv4rOABXSygHTsbvUz4G_YQhOb\">Stanford DL course</a></p>\n<p><a href=\"http://cs230.stanford.edu/syllabus/\">Syllabus</a></p>\n<p>This course is youtube videos + coursera videos. Youtube has deeper insights and coursera is for practice and fundamentals.</p>\n<h1 id=\"key-messages\">Key messages<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#key-messages\"></a></h1>\n<ul>\n<li>In deep learning, feature learning replaces feature engineering</li>\n<li>Traditional ML performance <strong>platues</strong> at some point and cannnot utilize more data. For NN we have not reached that point yet.</li>\n<li>ML,DL is all about approximating/learning a function.</li>\n<li>Model = Architecture + Parameters</li>\n<li>Gradient evaluated at particular point = slope of the tangent at particular point</li>\n<li>Gradient checking (e.g if the signs changes often) is a good way to see if your optimization of the loss function is divergent.</li>\n<li>Backprogation is just an application of the chain rule.</li>\n<li>Backpropagation is used to calculate the gradient of the loss function with respect to the parameters. </li>\n<li>ReLU is the most common activation function</li>\n<li>Sigmoid is almost never used for hidden layers, tanh is almost always better choice</li>\n<li>NN require random initialization</li>\n<li>Aim to have yur validation and test set coming from the same distribution.</li>\n<li>L2 regularization is also called weight decay <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>w</mi><mo>=</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mstyle displaystyle=\"true\" scriptlevel=\"0\"><mfrac><mrow><mi>α</mi><mi>λ</mi></mrow><mi>n</mi></mfrac></mstyle><mo stretchy=\"false\">)</mo><mi>w</mi><mo>−</mo><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>m</mi><mi>s</mi></mrow><annotation encoding=\"application/x-tex\">w = (1-\\dfrac{\\alpha\\lambda}{n})w - other terms</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0574em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">n</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord mathnormal\">λ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">s</span></span></span></span></span></li>\n<li>Sanity checks for your NN:\n<ul>\n<li>cost is decreasing as number of iterations increase (if using dropout, might not be the case)</li>\n<li>gradient checking  </li>\n</ul>\n</li>\n<li>Regularization is used to reduce overfitting\n<ul>\n<li>L1, L2</li>\n<li>Dropout</li>\n<li>Data augmentation (add more data, rotate image, add some noise, flip image, blur image )</li>\n<li>Early stopping</li>\n</ul>\n</li>\n<li>Orthogonalisation idea one task at a time. (First focus on minimizing the cost function (overfit!). Then focus on regularization.)</li>\n<li>Normalize inputs for NN to converge more quickly</li>\n<li>Careful choice of weights initialization can solve vanishing/exploding gradients</li>\n<li>Gradient tracking</li>\n<li><a href=\"https://arxiv.org/abs/1502.01852\">https://arxiv.org/abs/1502.01852</a></li>\n</ul>\n<h1 id=\"lecture-1-deep-learning-overview\">Lecture 1 Deep Learning overview<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#lecture-1-deep-learning-overview\"></a></h1>\n<p>Deep Learning and Neural Network are almost the same thing. DL is the popular brand word.</p>\n<p>Traditional ML performance <strong>platues</strong> at some point and cannnot utilize more data. For NN we have not reached that point yet.</p>\n<p><img src=\"/dendron-wiki/assets/images/ML_DL_performance.png\"></p>\n<p><strong>Fundamental courses:</strong></p>\n<ul>\n<li>CS229 (ML most mathematical)</li>\n<li>CS299A (Applied ML least mathematical and easiest)</li>\n<li>CS230 (a bit in between, focuses on DL)</li>\n</ul>\n<p>Finish C1M1, C1M2 (chap 1 module 2).</p>\n<h1 id=\"lecture-2-deep-learning-intuition\">Lecture 2: Deep Learning Intuition<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#lecture-2-deep-learning-intuition\"></a></h1>\n<p>ML,DL is all about approximating/learning a function.</p>\n<p><strong>Model = Architecture + Parameters</strong></p>\n<p>The goal of ML/DL is to find the best parameters for the model.</p>\n<p>Example:</p>\n<p><img src=\"/dendron-wiki/assets/images/lg_nn.png\"></p>\n<p><strong>Each hidden layer encodes information from previous layer. E.g in convolutional neural network, each layer encodes more and more complex features. </strong></p>\n<p><img src=\"/dendron-wiki/assets/images/cnn_encoding.png\"></p>\n<h2 id=\"case-study-1-day-and-night-classification\">Case study 1: Day and Night classification<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#case-study-1-day-and-night-classification\"></a></h2>\n<p><strong>Deep Learning Project choices:</strong></p>\n<p><img src=\"/dendron-wiki/assets/images/dl_choices.png\"></p>\n<p>The problem of clasifying a cat needed 10,000 images. Is the next problem easier or harder? Depending  on the task you want to solve you would know based on past projets how many data point you need.</p>\n<ul>\n<li>train/test split 80/20 is good for 10k images. If I had 1M images I would choose 98/2 split. Test data is to gauge how well the model is doing on real unseen data. You ask yourself how many data points I need to tell my model is doing good (dawn, sunset, sunrise, evening, morning)</li>\n<li>bias you want balanced dataset in train and test</li>\n<li>resolution of images (the smaller the better for computation. 32x32 is better than 400x400) Choose the smallest resolution that human can have perfect performance. If you had unlimited computational power you would choose the highest resolution.</li>\n</ul>\n<h2 id=\"case-study-2-face-verification\">Case study 2: Face verification<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#case-study-2-face-verification\"></a></h2>\n<ul>\n<li>architecture: encode each image using a DL and then compute distance functions</li>\n<li>In face verification, we have used an encoder network to learn a lower\ndimensional representation (called “encoding”) for a set of data by\ntraining the network to focus on non-noisy signals.</li>\n<li><strong>Triplet loss</strong> is a loss function where an (anchor) input is compared to a\npositive input and a negative input. The distance from the anchor input to\nthe positive input is minimized, whereas the distance from the anchor input\nto the negative input is maximized.</li>\n</ul>\n<p><img src=\"/dendron-wiki/assets/images/face_verify1.png\"></p>\n<p><img src=\"/dendron-wiki/assets/images/face_verify2.png\"></p>\n<p><img src=\"/dendron-wiki/assets/images/face_verify3.png\"></p>\n<h2 id=\"case-study-3-art-generation\">Case study 3: Art generation<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#case-study-3-art-generation\"></a></h2>\n<ul>\n<li>Do not train model, just optimize the cost function by changing pixels (goal is to generate image)\nKian Katanforoosh</li>\n<li>In the neural style transfer algorithm proposed by Gatys et al., you optimize\nimage pixels rather than model parameters. Model parameters are\npretrained and non-trainable.</li>\n<li>You leverage the “knowledge” of a pretrained model to extract the content\nof a content image and the style of a style image</li>\n<li>ImageNet</li>\n<li>Take gradient of loss function with respect to the pixels <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">x</span></span></span></span></span>.</li>\n</ul>\n<p><img src=\"/dendron-wiki/assets/images/art_gen1.png\"></p>\n<p><img src=\"/dendron-wiki/assets/images/art_gen2.png\"></p>\n<p><img src=\"/dendron-wiki/assets/images/art_gen3.png\"></p>\n<h2 id=\"case-study-4-trigger-word-detection-alexa\">Case study 4: Trigger word detection (Alexa)<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#case-study-4-trigger-word-detection-alexa\"></a></h2>\n<ul>\n<li>Your data collection strategy is critical to the success of your project. (If\napplicable) Don’t hesitate to get out of the building.</li>\n<li>You can gain insights on your labelling strategy by using a human experiment</li>\n</ul>\n<p><img src=\"/dendron-wiki/assets/images/trigger_word.png\"></p>\n<p><img src=\"/dendron-wiki/assets/images/data_collection.png\"></p>\n<h1 id=\"lecture-3---full-cycle-deep-learning-projects\">Lecture 3 - Full-Cycle Deep Learning Projects<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#lecture-3---full-cycle-deep-learning-projects\"></a></h1>\n<ol>\n<li>Select problem (e.g. supervised learning)</li>\n<li>Get data (need to be very strategic in that)</li>\n<li>Design model</li>\n<li>Train model (iterative process with point 2 and 3)</li>\n<li>Test model</li>\n<li>Deploy</li>\n<li>Maintain</li>\n</ol>\n<p>Five points when selecting a project:</p>\n<ul>\n<li>interest</li>\n<li>data availability</li>\n<li>domain knowledge</li>\n<li>feasibility</li>\n<li>Usefulness</li>\n</ul>\n<p>First goal when starting to build a ML system is to get a baseline as fast as possible. Then iterate on that. That is steps 1-5 should be done within a couple of days.</p>\n<p>ML developement is an iterative process. Before you start working on it it is difficult to know what are the hard problems you need to tackle</p>\n<p><strong>Tips:</strong></p>\n<ul>\n<li>keep clear notes on experiments runs</li>\n<li>generally when you have to make choice between multiple options - go with the simpler one first</li>\n<li>in real projects often data change over time. Non-ML models are more robust, ML models often need to be retrained.</li>\n</ul>\n<p>edge deployment vs cloud deployment</p>\n<h1 id=\"lecture-4---adversarial-attacks--gans\">Lecture 4 - Adversarial Attacks / GANs<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#lecture-4---adversarial-attacks--gans\"></a></h1>\n<p><strong>Discovery: Several ML models, including state-of-the-art neural networks are vulnerable to adversarial examples.</strong></p>\n<p>[Szegedy et al. (2013): Intriguing properties of neural networks]</p>\n<p>[Ian J. Goodfellow, Jonathon Shlens &#x26; Christian Szegedy (2015): Explaining and harnessing adversarial examples]</p>\n<h2 id=\"attacking-a-network-with-adversarial-examples\">Attacking a network with adversarial examples<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#attacking-a-network-with-adversarial-examples\"></a></h2>\n<p>What are examples of Adversarial attacks?</p>\n<p>Given a network pretrained on ImageNet, find an input image that is not a iguana but will be classified as iguana.</p>\n<p>Attack:</p>\n<ol>\n<li>Start with some image that is not iguana.</li>\n<li>Use pretrained NN and output a vector of probabilities (cat, dog, iguana..)</li>\n<li>Compute Loss.</li>\n<li>Take gradient of loss wrt to the pixels. (backpropagation, need to have access to the model, parameters, layers etc.)</li>\n<li>Change the image pixels.</li>\n</ol>\n<p><img src=\"/dendron-wiki/assets/images/adversarial_examples.png\"></p>\n<p>You can see that chaning with very little the pixels in the image you can fool the network that the cat is an iguana.</p>\n<p><img src=\"/dendron-wiki/assets/images/space_images.png\"></p>\n<h2 id=\"defense-against-a-network-with-adversarial-examples\">Defense against a network with adversarial examples<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#defense-against-a-network-with-adversarial-examples\"></a></h2>\n<ol>\n<li>Add a SafetyNet - one more NN that will detect adversarial examples. (but it can be fooled as well) [Yuan et al. (2017): Adversarial Examples: Attacks and Defenses for Deep Learning]</li>\n<li>Train on corrrectly labelled adversarial examples. Generate adversarial examples and train on them.</li>\n</ol>\n<h2 id=\"why-are-nn-vulnarable-to-adversarial-examples\">Why are NN vulnarable to adversarial examples?<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#why-are-nn-vulnarable-to-adversarial-examples\"></a></h2>\n<p><a href=\"https://arxiv.org/pdf/1712.07107.pdf\">Adversarial Examples: Attacks and Defenses for Deep Learning</a></p>\n<p>You'd think that NN are vulnaraalbe because they are too complex and overfit the data. But it turns out that the linearity part of the network is the problem.</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi><mo>=</mo><mi>x</mi><mi>w</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">y = xw+b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span></span></p>\n<p>It is easy to create <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>x</mi><mo lspace=\"0em\" rspace=\"0em\">∗</mo></msup><mo>=</mo><mi>x</mi><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding=\"application/x-tex\">x^{*}=x+\\epsilon</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6887em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6887em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">∗</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">ϵ</span></span></span></span></span> which would produce massively different y.</p>\n<p><strong>Fast Gradient Sign Method</strong> is a method to create quickly adversarial examples.</p>\n<h2 id=\"gan---generative-adversarial-networks\">GAN - Generative Adversarial Networks<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#gan---generative-adversarial-networks\"></a></h2>\n<p>The word adversarial is used in different meaning here. In GANs it means that there are two networks that are competing with each other.</p>\n<p>GAN-s are networks that generate images that mimic the distribution of the real images/data.</p>\n<h3 id=\"gd-game\">G/D game<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#gd-game\"></a></h3>\n<p>Generator (is what we want to train and generate fake images),</p>\n<p>Disriminator</p>\n<p>G wants to fool D. D catches fake images. In the beginning it would be very good at catching fake images. But G will learn to generate better images. G and D are trained together.</p>\n<p>Min-max trick of chaning the loss function</p>\n<p>Saturating cost vs non-saturating cost </p>\n<p>If D does not improve G cannot improve. You can see D as an upper bound on G.</p>\n<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> num_iterations<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>k_steps<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        update D\n    update G\n</code></pre>\n<p>Tips for training GAN-s:</p>\n<ul>\n<li>modify loss function</li>\n<li>keep D up-to-date with respect to G (k update for G and 1 update for D)</li>\n<li>Virtual Batchnorm</li>\n<li>one-sided label smoothing</li>\n</ul>\n<p>CycleGAN</p>\n<p>image with horses, generate same image with zebra.</p>\n<p>Loss function contains all losses from normal gans + cycle loss. </p>\n<p><img src=\"/dendron-wiki/assets/images/cycle_gan.png\"></p>","noteIndex":{"id":"wn8PE1RhG0znK1alrGFYv","title":"Root","desc":"","updated":1763992060664,"created":1631901573363,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"dc095b340c158394d643b84f8585ff0c","links":[],"anchors":{},"children":["dgcsvcwea8scgdegrk9tfni","xig93vo47ou1bkr7s4w1wb2","ro9bbyftsutm88mxw6r16p5","ypia1zmywsklpicmcgrzlz1","w7iitlako61ppm27mym400a","6bx5plramu4hksomqc1n55z","4nki3bedlvs3mnkixj3a07k","9r5ym61dkwap92fvbte1jkq","849u97nrsuyekmr4a1r92ux","2b5bwf46z6v132wu7xghvrp","dygp5h2vzw4mkromwmofynb","7h50s7ga5ziiyblmoctsqmw","pglaolxcge4xfvgoph3je89","uy9u1co5ih1fokind8tg0eq","jc23ggp8iiu92kpnzo721to","f1u2a47guuw70olv36bzf66","c1bs7wsjfbhb0zipaywqv1","2av385tcj2cbumxprsauff3","lw1b4r6ykimvj9208nkgzps"],"parent":null,"data":{},"body":"\nZdr bebce kp ;)\n\nThis is my knowledge base, additionally I keep [daily journal](https://docs.google.com/document/d/1m8Npu0-t8RweyKiHCjLL1PPDYzbebqm3OZDHH8IVsb8/edit?tab=t.rj0kvkrm7zpr)."},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.95.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false,"templateHierarchy":"template"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","assetsPrefix":"/dendron-wiki","siteUrl":"https://ngocuong0105.github.io","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"theme":"light","templateVersion":"0.97.0","ga":{"tracking":"G-W5DRRLQ1N7"},"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}