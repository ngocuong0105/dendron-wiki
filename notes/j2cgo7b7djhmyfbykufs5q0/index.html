<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/dendron-wiki/favicon.ico"/><title>LLMs</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="LLMs"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://ngocuong0105.github.io/dendron-wiki/notes/j2cgo7b7djhmyfbykufs5q0/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="3/4/2025"/><meta property="article:modified_time" content="4/9/2025"/><link rel="canonical" href="https://ngocuong0105.github.io/dendron-wiki/notes/j2cgo7b7djhmyfbykufs5q0/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/dendron-wiki/_next/static/css/73bff7fc08ed1d26.css" as="style"/><link rel="stylesheet" href="/dendron-wiki/_next/static/css/73bff7fc08ed1d26.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/dendron-wiki/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/dendron-wiki/_next/static/chunks/webpack-5a49f804ab2869ab.js" defer=""></script><script src="/dendron-wiki/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/dendron-wiki/_next/static/chunks/main-2a75a40d33729b12.js" defer=""></script><script src="/dendron-wiki/_next/static/chunks/pages/_app-47f94d7e2ed9c5e2.js" defer=""></script><script src="/dendron-wiki/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/dendron-wiki/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/dendron-wiki/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/dendron-wiki/_next/static/AZXonBxzXDJ7mmxS9Br0O/_buildManifest.js" defer=""></script><script src="/dendron-wiki/_next/static/AZXonBxzXDJ7mmxS9Br0O/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="llms">LLMs<a aria-hidden="true" class="anchor-heading icon-link" href="#llms"></a></h1>
<p>Here I put all my thoughts, my resarch, things I've learned and read about LLMs.</p>
<h1 id="resources">Resources<a aria-hidden="true" class="anchor-heading icon-link" href="#resources"></a></h1>
<ul>
<li><a href="https://darioamodei.com/">Dario Modei Blog</a></li>
<li></li>
</ul>
<h1 id="models">Models<a aria-hidden="true" class="anchor-heading icon-link" href="#models"></a></h1>
<p>LLM models so far are decrtibed as reasoning and models that are good for creative tasks and agentic planning.</p>
<ul>
<li>DeepSeek-R1 chinese AI lab DeepSeek reasoning model</li>
<li></li>
</ul>
<h1 id="openai">OpenAI<a aria-hidden="true" class="anchor-heading icon-link" href="#openai"></a></h1>
<ul>
<li>gpt models, flagship models for OpenAI</li>
<li>o-series reasoning modeils</li>
</ul>
<p><a class="color-tag" style="--tag-color: #fbdd7e;" href="/dendron-wiki/notes/q334c9dkrbs70eq5gujgcb3">#TODO</a> <a href="https://platform.openai.com/docs/models#models-overview">https://platform.openai.com/docs/models#models-overview</a></p>
<h1 id="deepseek">DeepSeek<a aria-hidden="true" class="anchor-heading icon-link" href="#deepseek"></a></h1>
<h2 id="r1">R1<a aria-hidden="true" class="anchor-heading icon-link" href="#r1"></a></h2>
<ul>
<li><a href="https://huggingface.co/deepseek-ai/DeepSeek-R1">R1 HuggingFace model</a></li>
</ul>
<p>reasoning model with 671 billion parameters. Under MIT License.</p>
<p><a class="color-tag" style="--tag-color: #fbdd7e;" href="/dendron-wiki/notes/q334c9dkrbs70eq5gujgcb3">#TODO</a> <a href="https://huggingface.co/deepseek-ai/DeepSeek-R1">https://huggingface.co/deepseek-ai/DeepSeek-R1</a></p>
<h1 id="prompt-engineering">Prompt engineering<a aria-hidden="true" class="anchor-heading icon-link" href="#prompt-engineering"></a></h1>
<p><a class="color-tag" style="--tag-color: #fbdd7e;" href="/dendron-wiki/notes/q334c9dkrbs70eq5gujgcb3">#TODO</a> <a href="https://platform.openai.com/docs/guides/prompt-engineering">https://platform.openai.com/docs/guides/prompt-engineering</a></p>
<h1 id="dario-amodei">Dario Amodei<a aria-hidden="true" class="anchor-heading icon-link" href="#dario-amodei"></a></h1>
<p><a href="https://darioamodei.com">https://darioamodei.com</a></p>
<h1 id="three-dynamics-of-ai-development">Three Dynamics of AI Development<a aria-hidden="true" class="anchor-heading icon-link" href="#three-dynamics-of-ai-development"></a></h1>
<ol>
<li>Scaling laws</li>
</ol>
<ul>
<li>$1M model might solve 20% of important coding tasks</li>
<li>$10M model might solve 40%</li>
<li>$100M model might solve 60% and so on</li>
</ul>
<p>Another factor of 10 might be the differene between an undergraduate and PhD skill level.</p>
<ol start="2">
<li>Shifting the curve</li>
</ol>
<ul>
<li>improvement on model architecture (tweaks ontransforers that the the underlying of today's models)</li>
<li>engineering improvements, finding a way to run the model more efficiently on the underlying hardware</li>
<li>CM = "compute multiplier". Frontier AI companies are able to find those compute multiplers</li>
</ul>
<ol start="3">
<li>Shifting the paradigm</li>
</ol>
<ul>
<li>From 2020-2023 the main thing being scaled was pretrained models</li>
<li>In 2024 the idea of using reinforecement learning to train models to generate chains of thought has become the new focus of scaling</li>
<li>new paradigm involves starting with the ordinary type of pretrained models, and then as a second stage using RL to add the reasoning skills</li>
<li>as of 2025 we are at a unique "crossover point" where thre is a powerful new paradigm that is early on the scaling curve and threfore can make big gains quickly.</li>
</ul>
<ul>
<li><a href="https://darioamodei.com/on-deepseek-and-export-controls">read section after DeepSeek's Models</a></li>
</ul>
<h1 id="industry-impact">Industry impact<a aria-hidden="true" class="anchor-heading icon-link" href="#industry-impact"></a></h1>
<p>The "developer loop" might change substantially.  I.e., today if you're doing a large task you might do something like:</p>
<ol>
<li>Work with your PM to figure out what they want</li>
<li>Write some code</li>
<li>Iterate with PM that you've built the thing they want</li>
<li>Iterate on a WIP PR with your technical stakeholders</li>
<li>Write some tests</li>
<li>Do more iteration on PR</li>
</ol>
<p>Where in the future/soon/now it might be more like</p>
<ol>
<li>Work with PM (and maybe the AI) to figure out what they want</li>
<li>Work with AI and your technical stakeholders to translate that PM plan to create a technical plan</li>
<li>Have AI implement a large fraction of the technical plan via chaos coding</li>
<li>Do some cleanup on the PR</li>
</ol>
<h1 id="pdoom">P(doom)<a aria-hidden="true" class="anchor-heading icon-link" href="#pdoom"></a></h1>
<p>median 5% , 14.4% average from AI CEOs and researchers responses.</p></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#resources" title="Resources">Resources</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#models" title="Models">Models</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#openai" title="OpenAI">OpenAI</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#deepseek" title="DeepSeek">DeepSeek</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#r1" title="R1">R1</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#prompt-engineering" title="Prompt engineering">Prompt engineering</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#dario-amodei" title="Dario Amodei">Dario Amodei</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#three-dynamics-of-ai-development" title="Three Dynamics of AI Development">Three Dynamics of AI Development</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#industry-impact" title="Industry impact">Industry impact</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#pdoom" title="P(doom)">P(doom)</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"j2cgo7b7djhmyfbykufs5q0","title":"LLMs","desc":"","updated":1744221423484,"created":1741085524865,"custom":{},"fname":"engineering.LLMs","type":"note","vault":{"fsPath":"vault"},"contentHash":"d0d4c8661307edcfc70b8c37d598e926","links":[{"type":"wiki","from":{"fname":"engineering.LLMs","id":"j2cgo7b7djhmyfbykufs5q0","vaultName":"vault"},"value":"tags.TODO","alias":"#TODO","position":{"start":{"line":18,"column":1,"offset":405},"end":{"line":18,"column":6,"offset":410},"indent":[]},"xvault":false,"to":{"fname":"tags.TODO"}},{"type":"wiki","from":{"fname":"engineering.LLMs","id":"j2cgo7b7djhmyfbykufs5q0","vaultName":"vault"},"value":"tags.TODO","alias":"#TODO","position":{"start":{"line":30,"column":1,"offset":628},"end":{"line":30,"column":6,"offset":633},"indent":[]},"xvault":false,"to":{"fname":"tags.TODO"}},{"type":"wiki","from":{"fname":"engineering.LLMs","id":"j2cgo7b7djhmyfbykufs5q0","vaultName":"vault"},"value":"tags.TODO","alias":"#TODO","position":{"start":{"line":34,"column":1,"offset":704},"end":{"line":34,"column":6,"offset":709},"indent":[]},"xvault":false,"to":{"fname":"tags.TODO"}}],"anchors":{"resources":{"type":"header","text":"Resources","value":"resources","line":10,"column":0,"depth":1},"models":{"type":"header","text":"Models","value":"models","line":14,"column":0,"depth":1},"openai":{"type":"header","text":"OpenAI","value":"openai","line":20,"column":0,"depth":1},"deepseek":{"type":"header","text":"DeepSeek","value":"deepseek","line":28,"column":0,"depth":1},"r1":{"type":"header","text":"R1","value":"r1","line":30,"column":0,"depth":2},"prompt-engineering":{"type":"header","text":"Prompt engineering","value":"prompt-engineering","line":38,"column":0,"depth":1},"dario-amodei":{"type":"header","text":"Dario Amodei","value":"dario-amodei","line":42,"column":0,"depth":1},"three-dynamics-of-ai-development":{"type":"header","text":"Three Dynamics of AI Development","value":"three-dynamics-of-ai-development","line":46,"column":0,"depth":1},"industry-impact":{"type":"header","text":"Industry impact","value":"industry-impact","line":69,"column":0,"depth":1},"pdoom":{"type":"header","text":"P(doom)","value":"pdoom","line":85,"column":0,"depth":1}},"children":[],"parent":"6bx5plramu4hksomqc1n55z","data":{}},"body":"\u003ch1 id=\"llms\"\u003eLLMs\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#llms\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eHere I put all my thoughts, my resarch, things I've learned and read about LLMs.\u003c/p\u003e\n\u003ch1 id=\"resources\"\u003eResources\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#resources\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://darioamodei.com/\"\u003eDario Modei Blog\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"models\"\u003eModels\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#models\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eLLM models so far are decrtibed as reasoning and models that are good for creative tasks and agentic planning.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDeepSeek-R1 chinese AI lab DeepSeek reasoning model\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"openai\"\u003eOpenAI\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#openai\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003egpt models, flagship models for OpenAI\u003c/li\u003e\n\u003cli\u003eo-series reasoning modeils\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca class=\"color-tag\" style=\"--tag-color: #fbdd7e;\" href=\"/dendron-wiki/notes/q334c9dkrbs70eq5gujgcb3\"\u003e#TODO\u003c/a\u003e \u003ca href=\"https://platform.openai.com/docs/models#models-overview\"\u003ehttps://platform.openai.com/docs/models#models-overview\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"deepseek\"\u003eDeepSeek\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#deepseek\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003ch2 id=\"r1\"\u003eR1\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#r1\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1\"\u003eR1 HuggingFace model\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003ereasoning model with 671 billion parameters. Under MIT License.\u003c/p\u003e\n\u003cp\u003e\u003ca class=\"color-tag\" style=\"--tag-color: #fbdd7e;\" href=\"/dendron-wiki/notes/q334c9dkrbs70eq5gujgcb3\"\u003e#TODO\u003c/a\u003e \u003ca href=\"https://huggingface.co/deepseek-ai/DeepSeek-R1\"\u003ehttps://huggingface.co/deepseek-ai/DeepSeek-R1\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"prompt-engineering\"\u003ePrompt engineering\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#prompt-engineering\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e\u003ca class=\"color-tag\" style=\"--tag-color: #fbdd7e;\" href=\"/dendron-wiki/notes/q334c9dkrbs70eq5gujgcb3\"\u003e#TODO\u003c/a\u003e \u003ca href=\"https://platform.openai.com/docs/guides/prompt-engineering\"\u003ehttps://platform.openai.com/docs/guides/prompt-engineering\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"dario-amodei\"\u003eDario Amodei\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#dario-amodei\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://darioamodei.com\"\u003ehttps://darioamodei.com\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"three-dynamics-of-ai-development\"\u003eThree Dynamics of AI Development\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#three-dynamics-of-ai-development\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003col\u003e\n\u003cli\u003eScaling laws\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e$1M model might solve 20% of important coding tasks\u003c/li\u003e\n\u003cli\u003e$10M model might solve 40%\u003c/li\u003e\n\u003cli\u003e$100M model might solve 60% and so on\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eAnother factor of 10 might be the differene between an undergraduate and PhD skill level.\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eShifting the curve\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eimprovement on model architecture (tweaks ontransforers that the the underlying of today's models)\u003c/li\u003e\n\u003cli\u003eengineering improvements, finding a way to run the model more efficiently on the underlying hardware\u003c/li\u003e\n\u003cli\u003eCM = \"compute multiplier\". Frontier AI companies are able to find those compute multiplers\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003eShifting the paradigm\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eFrom 2020-2023 the main thing being scaled was pretrained models\u003c/li\u003e\n\u003cli\u003eIn 2024 the idea of using reinforecement learning to train models to generate chains of thought has become the new focus of scaling\u003c/li\u003e\n\u003cli\u003enew paradigm involves starting with the ordinary type of pretrained models, and then as a second stage using RL to add the reasoning skills\u003c/li\u003e\n\u003cli\u003eas of 2025 we are at a unique \"crossover point\" where thre is a powerful new paradigm that is early on the scaling curve and threfore can make big gains quickly.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://darioamodei.com/on-deepseek-and-export-controls\"\u003eread section after DeepSeek's Models\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"industry-impact\"\u003eIndustry impact\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#industry-impact\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eThe \"developer loop\" might change substantially.  I.e., today if you're doing a large task you might do something like:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eWork with your PM to figure out what they want\u003c/li\u003e\n\u003cli\u003eWrite some code\u003c/li\u003e\n\u003cli\u003eIterate with PM that you've built the thing they want\u003c/li\u003e\n\u003cli\u003eIterate on a WIP PR with your technical stakeholders\u003c/li\u003e\n\u003cli\u003eWrite some tests\u003c/li\u003e\n\u003cli\u003eDo more iteration on PR\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eWhere in the future/soon/now it might be more like\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eWork with PM (and maybe the AI) to figure out what they want\u003c/li\u003e\n\u003cli\u003eWork with AI and your technical stakeholders to translate that PM plan to create a technical plan\u003c/li\u003e\n\u003cli\u003eHave AI implement a large fraction of the technical plan via chaos coding\u003c/li\u003e\n\u003cli\u003eDo some cleanup on the PR\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch1 id=\"pdoom\"\u003eP(doom)\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#pdoom\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003emedian 5% , 14.4% average from AI CEOs and researchers responses.\u003c/p\u003e","noteIndex":{"id":"wn8PE1RhG0znK1alrGFYv","title":"Root","desc":"","updated":1763992060664,"created":1631901573363,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"dc095b340c158394d643b84f8585ff0c","links":[],"anchors":{},"children":["dgcsvcwea8scgdegrk9tfni","xig93vo47ou1bkr7s4w1wb2","ro9bbyftsutm88mxw6r16p5","ypia1zmywsklpicmcgrzlz1","w7iitlako61ppm27mym400a","6bx5plramu4hksomqc1n55z","4nki3bedlvs3mnkixj3a07k","9r5ym61dkwap92fvbte1jkq","849u97nrsuyekmr4a1r92ux","2b5bwf46z6v132wu7xghvrp","dygp5h2vzw4mkromwmofynb","7h50s7ga5ziiyblmoctsqmw","pglaolxcge4xfvgoph3je89","uy9u1co5ih1fokind8tg0eq","jc23ggp8iiu92kpnzo721to","f1u2a47guuw70olv36bzf66","c1bs7wsjfbhb0zipaywqv1","2av385tcj2cbumxprsauff3","lw1b4r6ykimvj9208nkgzps"],"parent":null,"data":{},"body":"\nZdr bebce kp ;)\n\nThis is my knowledge base, additionally I keep [daily journal](https://docs.google.com/document/d/1m8Npu0-t8RweyKiHCjLL1PPDYzbebqm3OZDHH8IVsb8/edit?tab=t.rj0kvkrm7zpr)."},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.95.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false,"templateHierarchy":"template"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","assetsPrefix":"/dendron-wiki","siteUrl":"https://ngocuong0105.github.io","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"theme":"light","templateVersion":"0.97.0","ga":{"tracking":"G-W5DRRLQ1N7"},"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"j2cgo7b7djhmyfbykufs5q0"},"buildId":"AZXonBxzXDJ7mmxS9Br0O","assetPrefix":"/dendron-wiki","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>