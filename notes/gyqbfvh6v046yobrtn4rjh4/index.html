<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/dendron-wiki/favicon.ico"/><title>Loss Functions</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="Loss Functions"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://ngocuong0105.github.io/dendron-wiki/notes/gyqbfvh6v046yobrtn4rjh4/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="3/10/2023"/><meta property="article:modified_time" content="3/27/2023"/><link rel="canonical" href="https://ngocuong0105.github.io/dendron-wiki/notes/gyqbfvh6v046yobrtn4rjh4/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/dendron-wiki/_next/static/css/73bff7fc08ed1d26.css" as="style"/><link rel="stylesheet" href="/dendron-wiki/_next/static/css/73bff7fc08ed1d26.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/dendron-wiki/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/dendron-wiki/_next/static/chunks/webpack-5a49f804ab2869ab.js" defer=""></script><script src="/dendron-wiki/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/dendron-wiki/_next/static/chunks/main-2a75a40d33729b12.js" defer=""></script><script src="/dendron-wiki/_next/static/chunks/pages/_app-28855ac016325484.js" defer=""></script><script src="/dendron-wiki/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/dendron-wiki/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/dendron-wiki/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/dendron-wiki/_next/static/hUMuUtBSCkU7YSeQn-rle/_buildManifest.js" defer=""></script><script src="/dendron-wiki/_next/static/hUMuUtBSCkU7YSeQn-rle/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="loss-functions">Loss Functions<a aria-hidden="true" class="anchor-heading icon-link" href="#loss-functions"></a></h1>
<h1 id="huber-loss">Huber Loss<a aria-hidden="true" class="anchor-heading icon-link" href="#huber-loss"></a></h1>
<p><a href="https://en.wikipedia.org/wiki/Huber_loss#:~:text=absolute%20value%20function">Wikipedia</a>.-,Pseudo%2DHuber%20loss%20function,less%20steep%20for%20extreme%20values.)</p>
<p>Huber loss is a combination of L1 and L2 loss functions. It is less sensitive to outliers in data than the squared error loss.</p>
<p>pseudo huber loss allows you to control the smoothness and therefore you can specifically decide how much you penalise outliers by, whereas huber loss is either MSE or MAE</p>
<h2 id="how-to-choose-the-hyper-parameter-delta">How to choose the hyper parameter delta?<a aria-hidden="true" class="anchor-heading icon-link" href="#how-to-choose-the-hyper-parameter-delta"></a></h2>
<p>Huber loss will clip gradients to delta for residual (abs) values larger than delta. You want that when some part of your data points poorly fit the model and you would like to limit their influence. Also, clipping the grads is a common way to make optimization stable (not necessarily with huber).
<a href="https://stats.stackexchange.com/questions/465937/how-to-choose-delta-parameter-in-huber-loss-function">StackExchange</a></p>
<h1 id="l1-vs-l2-regularization">L1 vs L2 regularization<a aria-hidden="true" class="anchor-heading icon-link" href="#l1-vs-l2-regularization"></a></h1>
<p>The best advice in data science is always try both and see what produces better CV and LB.</p>
<p>I think L1 shines when we approach "the curse of dimensionality" (i.e. when the number of train rows is small compared with number of train columns). I think a rule of thumb is when number of features (i.e. columns) is anywhere near 1/10th (or larger) the number of training samples (i.e. rows) we approach the "the curse of dimensionality".</p></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#huber-loss" title="Huber Loss">Huber Loss</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#how-to-choose-the-hyper-parameter-delta" title="How to choose the hyper parameter delta?">How to choose the hyper parameter delta?</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#l1-vs-l2-regularization" title="L1 vs L2 regularization">L1 vs L2 regularization</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"gyqbfvh6v046yobrtn4rjh4","title":"Loss Functions","desc":"","updated":1679935870151,"created":1678472987738,"custom":{},"fname":"machine learning.Loss Functions","type":"note","vault":{"fsPath":"vault"},"contentHash":"f49900328dc76ce646a974f292a2c28e","links":[],"anchors":{"huber-loss":{"type":"header","text":"Huber Loss","value":"huber-loss","line":8,"column":0,"depth":1},"how-to-choose-the-hyper-parameter-delta":{"type":"header","text":"How to choose the hyper parameter delta?","value":"how-to-choose-the-hyper-parameter-delta","line":15,"column":0,"depth":2},"l1-vs-l2-regularization":{"type":"header","text":"L1 vs L2 regularization","value":"l1-vs-l2-regularization","line":20,"column":0,"depth":1}},"children":[],"parent":"2b5bwf46z6v132wu7xghvrp","data":{}},"body":"\u003ch1 id=\"loss-functions\"\u003eLoss Functions\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#loss-functions\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003ch1 id=\"huber-loss\"\u003eHuber Loss\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#huber-loss\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Huber_loss#:~:text=absolute%20value%20function\"\u003eWikipedia\u003c/a\u003e.-,Pseudo%2DHuber%20loss%20function,less%20steep%20for%20extreme%20values.)\u003c/p\u003e\n\u003cp\u003eHuber loss is a combination of L1 and L2 loss functions. It is less sensitive to outliers in data than the squared error loss.\u003c/p\u003e\n\u003cp\u003epseudo huber loss allows you to control the smoothness and therefore you can specifically decide how much you penalise outliers by, whereas huber loss is either MSE or MAE\u003c/p\u003e\n\u003ch2 id=\"how-to-choose-the-hyper-parameter-delta\"\u003eHow to choose the hyper parameter delta?\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#how-to-choose-the-hyper-parameter-delta\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eHuber loss will clip gradients to delta for residual (abs) values larger than delta. You want that when some part of your data points poorly fit the model and you would like to limit their influence. Also, clipping the grads is a common way to make optimization stable (not necessarily with huber).\n\u003ca href=\"https://stats.stackexchange.com/questions/465937/how-to-choose-delta-parameter-in-huber-loss-function\"\u003eStackExchange\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"l1-vs-l2-regularization\"\u003eL1 vs L2 regularization\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#l1-vs-l2-regularization\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eThe best advice in data science is always try both and see what produces better CV and LB.\u003c/p\u003e\n\u003cp\u003eI think L1 shines when we approach \"the curse of dimensionality\" (i.e. when the number of train rows is small compared with number of train columns). I think a rule of thumb is when number of features (i.e. columns) is anywhere near 1/10th (or larger) the number of training samples (i.e. rows) we approach the \"the curse of dimensionality\".\u003c/p\u003e","noteIndex":{"id":"wn8PE1RhG0znK1alrGFYv","title":"Root","desc":"","updated":1744237493819,"created":1631901573363,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"ea936af1aea818f3052610daac103a63","links":[],"anchors":{},"children":["dgcsvcwea8scgdegrk9tfni","xig93vo47ou1bkr7s4w1wb2","ro9bbyftsutm88mxw6r16p5","ypia1zmywsklpicmcgrzlz1","w7iitlako61ppm27mym400a","6bx5plramu4hksomqc1n55z","4nki3bedlvs3mnkixj3a07k","9r5ym61dkwap92fvbte1jkq","849u97nrsuyekmr4a1r92ux","2b5bwf46z6v132wu7xghvrp","dygp5h2vzw4mkromwmofynb","7h50s7ga5ziiyblmoctsqmw","pglaolxcge4xfvgoph3je89","uy9u1co5ih1fokind8tg0eq","jc23ggp8iiu92kpnzo721to","f1u2a47guuw70olv36bzf66","c1bs7wsjfbhb0zipaywqv1","2av385tcj2cbumxprsauff3","v77wdzobzcackzimz6a7crv"],"parent":null,"data":{},"body":"\nWelcome to my Knowledge Base! Here I write about my perception of life, document exciting things I've learned, debate (with myself) on controversial topics. If you know me you will not be surprised to find out that I write mostly about engineering and maths. Other topics I'm interested in are economics, politics, business, chess and poker."},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.95.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false,"templateHierarchy":"template"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","assetsPrefix":"/dendron-wiki","siteUrl":"https://ngocuong0105.github.io","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"theme":"light","templateVersion":"0.97.0","ga":{"tracking":"G-W5DRRLQ1N7"},"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"gyqbfvh6v046yobrtn4rjh4"},"buildId":"hUMuUtBSCkU7YSeQn-rle","assetPrefix":"/dendron-wiki","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>