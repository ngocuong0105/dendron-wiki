<h1 id="2025-04-18">2025-04-18<a aria-hidden="true" class="anchor-heading icon-link" href="#2025-04-18"></a></h1>
<h1 id="chain-of-thought">Chain of Thought<a aria-hidden="true" class="anchor-heading icon-link" href="#chain-of-thought"></a></h1>
<p><a href="https://openai.com/index/learning-to-reason-with-llms/">o1 release</a></p>
<ul>
<li>Essentially the model has been trained on how to think and it goes through an explicit reasoning process before giving its final answer.</li>
<li>The tradeoff being made is:</li>
<li>Vastly improved problem solving capabilities for queries where there are verifiably correct answers.</li>
<li>100x or more slower than non-reasoning models since the LLM is producing all those internal reasoning tokens.  A “fast” query with a reasoning model is 10s before you get any output.  A slow query is minutes.</li>
<li>5x more expensive than non-reasoning models.</li>
<li>This tradeoff is tunable.  The longer you let the model reason, the more capable it is.</li>
<li><strong>Important</strong> The reasoning models do NOT improve the capabilities for subjective tasks.  OpenAI even observed that people tend to prefer the text of gpt-4o vs o1.  The improved capabilities are just for when there are verifiably correct answers.</li>
</ul>
<h1 id="hot-pot-and-poke">Hot Pot and Poke<a aria-hidden="true" class="anchor-heading icon-link" href="#hot-pot-and-poke"></a></h1>
<p>Newfounland viewing 536 flats, 97% occupancy, hey tea and zara.</p>
<p>Hot Pot was disappointing. Poke was ok-ish - at least the salmon was good, chicken not great.</p>
<p>Drank and had fun. Luckily not too drank. </p>