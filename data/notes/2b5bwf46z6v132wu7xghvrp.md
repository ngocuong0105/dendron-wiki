# Articles
[ML algos](https://towardsdatascience.com/all-machine-learning-algorithms-you-should-know-for-2023-843dba11419c)

# Kaggle

- [Repo](https://github.com/ngocuong0105/kaggle)
- [[machine learning.Kaggle tricks]]


Steps:
1. EDA
2. Feature engineering
3. Build ML model
4. Model validation


**[random_state parameter](https://scikit-learn.org/stable/glossary.html#term-random_state:~:text=random_state-,%C2%B6,-%C2%B6)**

Many machine learning models allow some randomness in model training. Specifying a number for random_state ensures you get the same results in each run. You use any number, and model quality won't depend meaningfully on exactly what value you choose.

**Underfitting vs overfitting**

Control the balance between these two using max leaves and max tree depth parameters in decision trees.

# MLOps

[Weights and Biases](https://www.kaggle.com/code/ayuraj/experiment-tracking-with-weights-and-biases/notebook)